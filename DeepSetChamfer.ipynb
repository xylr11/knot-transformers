{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb263b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from pytorch_lightning import Trainer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d6dcd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_knot_data(filename):\n",
    "    records = []\n",
    "    \n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            # 1) Convert curly braces to square brackets\n",
    "            line = line.replace('{', '[').replace('}', ']')\n",
    "            \n",
    "            # 2) Convert Mathematica *^ floats to Python e floats\n",
    "            #    Do each sign separately, then default to no sign\n",
    "            line = line.replace('*^-', 'e-')\n",
    "            line = line.replace('*^+', 'e+')\n",
    "            line = line.replace('*^', 'e')\n",
    "            \n",
    "            # 3) literal_eval\n",
    "            data = ast.literal_eval(line)\n",
    "            records.append(data)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(records, columns=[\"knot_name\", \"J_zeros\", \"C_zeros\", \"volume\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f8720ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_knots=read_knot_data(\"nameJ2zerosJ3zerosvol.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4a53cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_complex_pairs(pair_list):\n",
    "    \"\"\"\n",
    "    Given a list of [real, imag] pairs, \n",
    "    sort them first by real component, then by imaginary component.\n",
    "    \"\"\"\n",
    "    if not pair_list:\n",
    "        return pair_list\n",
    "    # Use Python's built-in 'sorted' with a tuple (real, imag) as the key\n",
    "    return sorted(pair_list, key=lambda pair: (pair[0], pair[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "931d001e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>knot_name</th>\n",
       "      <th>J_zeros</th>\n",
       "      <th>C_zeros</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4_1</td>\n",
       "      <td>[[-0.3090169943749479, -0.9510565162951543], [...</td>\n",
       "      <td>[[-0.9713385871308796, -0.2377001244227466], [...</td>\n",
       "      <td>2.029883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5_2</td>\n",
       "      <td>[[-0.33911004330436717, -0.8223754344096812], ...</td>\n",
       "      <td>[[-1.0758734219330786, -0.36954428316759746], ...</td>\n",
       "      <td>2.828122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6_1</td>\n",
       "      <td>[[-0.40662961271472337, -0.7490398002735331], ...</td>\n",
       "      <td>[[-1.0198202123407993, -0.3943807100072422], [...</td>\n",
       "      <td>3.163963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6_2</td>\n",
       "      <td>[[-0.49883183995589636, -1.001302556337741], [...</td>\n",
       "      <td>[[-1.0522537067062143, -0.36270316966133176], ...</td>\n",
       "      <td>4.400833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6_3</td>\n",
       "      <td>[[-0.40096886790241876, -0.9160916804409108], ...</td>\n",
       "      <td>[[-1.1795647308385209, 0], [-0.914211156015100...</td>\n",
       "      <td>5.693021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  knot_name                                            J_zeros  \\\n",
       "0       4_1  [[-0.3090169943749479, -0.9510565162951543], [...   \n",
       "1       5_2  [[-0.33911004330436717, -0.8223754344096812], ...   \n",
       "2       6_1  [[-0.40662961271472337, -0.7490398002735331], ...   \n",
       "3       6_2  [[-0.49883183995589636, -1.001302556337741], [...   \n",
       "4       6_3  [[-0.40096886790241876, -0.9160916804409108], ...   \n",
       "\n",
       "                                             C_zeros    volume  \n",
       "0  [[-0.9713385871308796, -0.2377001244227466], [...  2.029883  \n",
       "1  [[-1.0758734219330786, -0.36954428316759746], ...  2.828122  \n",
       "2  [[-1.0198202123407993, -0.3943807100072422], [...  3.163963  \n",
       "3  [[-1.0522537067062143, -0.36270316966133176], ...  4.400833  \n",
       "4  [[-1.1795647308385209, 0], [-0.914211156015100...  5.693021  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_knots['J_zeros'] = df_knots['J_zeros'].apply(sort_complex_pairs)\n",
    "df_knots['C_zeros'] = df_knots['C_zeros'].apply(sort_complex_pairs)\n",
    "df_knots.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f9d9429",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KnotsDataset(Dataset):\n",
    "    def __init__(self, df_knots, input_col='C_zeros', target_col='J_zeros'):\n",
    "        \"\"\"\n",
    "        df_knots: a pandas DataFrame.\n",
    "        input_col: name of the column containing the input list of [re, im] pairs.\n",
    "        target_col: name of the column containing the target list of [re, im] pairs.\n",
    "        \"\"\"\n",
    "        self.df_knots = df_knots.reset_index(drop=True)\n",
    "        self.input_col = input_col\n",
    "        self.target_col = target_col\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df_knots)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Return (x, y) where x is the list of [re, im] for J_roots_pos_imag,\n",
    "        and y is the list of [re, im] for C_roots_pos_imag.\n",
    "        \"\"\"\n",
    "        row = self.df_knots.iloc[idx]\n",
    "        x = row[self.input_col]  # a list of [real, imag]\n",
    "        y = row[self.target_col] # a list of [real, imag]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0aa5fb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knots_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    batch: list of (x, y), where:\n",
    "      x is a list of [re, im] floats,\n",
    "      y is a list of [re, im] floats.\n",
    "\n",
    "    Returns:\n",
    "      x_tensor: (batch_size, max_len, 2) float\n",
    "      x_mask:   (batch_size, max_len) bool  (True=valid, False=pad)\n",
    "      y_tensor: (batch_size, max_len, 3) float\n",
    "                where [re, im, 0] = valid\n",
    "                      [0,  0,  1] = padded\n",
    "    \"\"\"\n",
    "    # Separate out all x and y\n",
    "    x_list = [item[0] for item in batch]  # list of lists of [re, im]\n",
    "    y_list = [item[1] for item in batch]\n",
    "\n",
    "    batch_size = len(batch)\n",
    "    # Find the maximum lengths\n",
    "    max_len_x = max((len(x_seq) for x_seq in x_list), default=0)\n",
    "    max_len_y = max((len(y_seq) for y_seq in y_list), default=0)\n",
    "    max_len   = max(max_len_x, max_len_y)  # unify so we can compare 1:1\n",
    "\n",
    "    # Create tensors\n",
    "    x_tensor = torch.zeros((batch_size, max_len, 2), dtype=torch.float)\n",
    "    x_mask   = torch.zeros((batch_size, max_len), dtype=torch.bool)\n",
    "\n",
    "    # For y, we have an extra dimension for the \"valid/pad\" flag\n",
    "    y_tensor = torch.zeros((batch_size, max_len, 3), dtype=torch.float)\n",
    "\n",
    "    # Fill each row\n",
    "    for i, (x_seq, y_seq) in enumerate(zip(x_list, y_list)):\n",
    "        # --- Inputs ---\n",
    "        Lx = len(x_seq)\n",
    "        for j in range(Lx):\n",
    "            re_val, im_val = x_seq[j]\n",
    "            x_tensor[i, j, 0] = re_val\n",
    "            x_tensor[i, j, 1] = im_val\n",
    "            x_mask[i, j] = True  # Mark valid\n",
    "\n",
    "        # --- Targets ---\n",
    "        Ly = len(y_seq)\n",
    "        for j in range(Ly):\n",
    "            re_val, im_val = y_seq[j]\n",
    "            y_tensor[i, j, 0] = re_val\n",
    "            y_tensor[i, j, 1] = im_val\n",
    "            y_tensor[i, j, 2] = 0.0  # 0 => valid token\n",
    "\n",
    "        # Pad the remainder of y with an indicator 1.0 => padded\n",
    "        for j in range(Ly, max_len):\n",
    "            y_tensor[i, j, 2] = 1.0  # 1 => padded\n",
    "\n",
    "    return x_tensor, x_mask, y_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61a080a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valtest_df = train_test_split(df_knots, test_size=0.2, random_state=42)\n",
    "val_df, test_df = train_test_split(valtest_df, test_size=0.5, random_state=42)\n",
    "\n",
    "train_dataset = KnotsDataset(train_df, input_col='C_zeros', target_col='J_zeros')\n",
    "val_dataset = KnotsDataset(val_df, input_col='C_zeros', target_col='J_zeros')\n",
    "test_dataset = KnotsDataset(test_df, input_col='C_zeros', target_col='J_zeros')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0, collate_fn=knots_collate_fn)#, multiprocessing_context=\"forkserver\", persistent_workers=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True, num_workers=0, collate_fn=knots_collate_fn)#, multiprocessing_context=\"forkserver\", persistent_workers=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True, num_workers=0, collate_fn=knots_collate_fn)#, multiprocessing_context=\"forkserver\", persistent_workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fcf31529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of knots: 141836\n",
      "x_tensor shape: torch.Size([32, 67, 2])\n",
      "y_tensor shape: torch.Size([32, 67, 3])\n"
     ]
    }
   ],
   "source": [
    "num_knots = len(train_loader.dataset)\n",
    "print(\"Number of knots:\", num_knots)\n",
    "\n",
    "for x_tensor, x_mask, y_tensor in train_loader:\n",
    "    print(\"x_tensor shape:\", x_tensor.shape)  # (batch_size, max_len, 2)\n",
    "    print(\"y_tensor shape:\", y_tensor.shape)  # (batch_size, max_len, 3)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31672a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chamfer Distance Loss (simple version)\n",
    "def chamfer_loss(pred, target):\n",
    "    # pred, target: (B, N, 2) tensors\n",
    "    D = torch.cdist(pred, target)  # (B, N, N)\n",
    "    loss1 = D.min(dim=2)[0].mean(dim=1)  # pred -> target\n",
    "    loss2 = D.min(dim=1)[0].mean(dim=1)  # target -> pred\n",
    "    return (loss1 + loss2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "944bbc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepSets model\n",
    "class DeepSets(nn.Module):\n",
    "    def __init__(self, in_dim=2, hidden_dim=128, num_outputs=49):\n",
    "        super().__init__()\n",
    "        self.phi = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.rho = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 2 * num_outputs)\n",
    "        )\n",
    "        self.num_outputs = num_outputs\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        # x: (B, N, 2), mask: (B, N) bool\n",
    "        x = self.phi(x)            # (B, N, H)\n",
    "        mask = mask.unsqueeze(-1)  # (B, N, 1) for broadcasting\n",
    "        x = x * mask               # zero out padded elements\n",
    "        x = x.sum(dim=1)           # sum only valid elements\n",
    "        x = self.rho(x)            # (B, 2*num_outputs)\n",
    "        return x.view(-1, self.num_outputs, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38b6679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Loss = 0.1983\n",
      "Epoch 1: Train Loss = 0.1580\n",
      "Epoch 2: Train Loss = 0.1437\n",
      "Epoch 3: Train Loss = 0.1365\n",
      "Epoch 4: Train Loss = 0.1319\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "model = DeepSets(in_dim=2, hidden_dim=128, num_outputs=49)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for x_tensor, x_mask, y_tensor in train_loader:\n",
    "        # y_tensor: (B, max_len, 3), need to mask out padded entries\n",
    "        y_valid = y_tensor[:, :, 2] == 0  # shape (B, max_len)\n",
    "        y_real  = y_tensor[:, :, :2]      # shape (B, max_len, 2)\n",
    "\n",
    "        # Get valid target positions only\n",
    "        pred = model(x_tensor, x_mask)\n",
    "        y_valid = (y_tensor[:, :, 2] == 0)      # (B, max_len) bool mask\n",
    "        y_real = y_tensor[:, :, :2].float()    # (B, max_len, 2)\n",
    "\n",
    "        # Zero out padded entries in target\n",
    "        padded_target = y_real * y_valid.unsqueeze(-1).float()  # (B, max_len, 2)\n",
    "\n",
    "        loss = chamfer_loss(pred, padded_target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    print(f\"Epoch {epoch}: Train Loss = {train_loss:.4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "knot-transformers-kernel",
   "language": "python",
   "name": "knot-transformers-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
